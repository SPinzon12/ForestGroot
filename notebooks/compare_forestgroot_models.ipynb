{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸŒ³ ComparaciÃ³n de Modelos: ForestGroot YOLOv8 vs. YOLOv9\n",
        "\n",
        "## Integrantes:\n",
        "- **Juan Camilo Vargas**\n",
        "- **Samuel PinzÃ³n ValderrutÃ©n**\n",
        "- **Sebastian Diaz Noguera**\n",
        "\n",
        "![ForestGroot](https://i.ibb.co/WzNPDXN/Sin-t-tulo.png)"
      ],
      "metadata": {
        "id": "1fEYTArp6zmX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset Forestgroot**\n",
        "\n",
        "Para la creaciÃ³n de este dataset se recolectaron un total de 400 imÃ¡genes JPG de zonas adyacentes al Amazonas utilizando imÃ¡genes de [Google Earth](https://www.google.com/earth/). A continuaciÃ³n, se presenta una tabla que describe las clases identificadas en las imÃ¡genes recolectadas:\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "| **Clase**       | **DescripciÃ³n**                                        |\n",
        "|-----------------|--------------------------------------------------------|\n",
        "| deforestation   | Ãreas donde se observa la pÃ©rdida de bosques.          |\n",
        "| water           | Regiones que contienen rÃ­os y cuerpos de agua.         |\n",
        "| fire            | Zonas afectadas por incendios forestales.              |\n",
        "| urban           | Ãreas urbanas, incluyendo ciudades y asentamientos urbanos. |\n",
        "\n",
        "</div>\n",
        "\n",
        "Debido al desbalance de clase con las 400 imÃ¡genes se realizÃ³ un data augmentation en las siguientes clases para evitar este problema:\n",
        "\n",
        "- **urban:** 245 imÃ¡genes.\n",
        "- **fire:** 85 imÃ¡genes.\n",
        "- **water:** 100 imÃ¡genes.\n",
        "\n",
        "Se obtuvo un dataset con un total de **830** imÃ¡genes, donde se identificaron las siguientes cantidades despuÃ©s del etiquetado:\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "| Clase          | Cantidad |\n",
        "|----------------|----------|\n",
        "| deforestation  | 558      |\n",
        "| urban          | 511      |\n",
        "| fire           | 477      |\n",
        "| water          | 470      |\n",
        "\n",
        "</div>\n",
        "\n",
        "Posteriormente, se realizÃ³ el data augmentation con Roboflow y se obtuvo el dataset final con **1992** imÃ¡genes, distribuidas de la siguiente manera:\n",
        "\n",
        "- Conjunto de entrenamiento: **1743** imÃ¡genes.\n",
        "- Conjunto de prueba: **166** imÃ¡genes.\n",
        "- Conjunto de validaciÃ³n: **83** imÃ¡genes.\n",
        "\n",
        "**Ejemplo del Dataset:**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.ibb.co/nrfJFSW/deforestation-098.png\" alt=\"ForestGroot\" width=\"70%\">\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "IdM4Tg9JXJNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**YOLOv8**\n",
        "YOLOv8 es una versiÃ³n de la familia de algoritmos de detecciÃ³n de objetos conocida como You Only Look Once (YOLO). Este modelo destaca por su capacidad para equilibrar velocidad y precisiÃ³n en tareas de visiÃ³n artificial en tiempo real. YOLOv8 sigue este enfoque al no contar con capas densas, todas sus capas son convolucionales. Esto lo hace adecuado para escenarios donde el procesamiento en tiempo real es crucial.\n",
        "\n",
        "**Proceso de detecciÃ³n de objetos en YOLOv8:**\n",
        "\n",
        "1. **ExtracciÃ³n de caracterÃ­sticas:**\n",
        "   - La imagen se divide en una cuadrÃ­cula de celdas, y luego se utiliza una red neuronal convolucional para extraer caracterÃ­sticas de cada una.\n",
        "   - Estas caracterÃ­sticas representan la informaciÃ³n visual dentro de cada celda.\n",
        "\n",
        "2. **PredicciÃ³n de Cajas Delimitadoras y Clases:**\n",
        "   - Para cada celda de la cuadrÃ­cula, YOLOv8 predice un nÃºmero fijo de cajas delimitadoras y las probabilidades de las clases correspondientes.\n",
        "   - Cada caja delimitadora contiene informaciÃ³n sobre la posiciÃ³n (coordenadas x, y, ancho y alto) y la confianza de detecciÃ³n.\n",
        "\n",
        "3. **SupresiÃ³n de No MÃ¡ximos (NMS):**\n",
        "   - Se aplica NMS para eliminar detecciones redundantes y mantener solo las detecciones mÃ¡s confiables.\n",
        "   - Durante este proceso, se selecciona la caja delimitadora con la mayor probabilidad de objeto y se eliminan las demÃ¡s cajas que tienen una superposiciÃ³n significativa con ella.\n",
        "\n",
        "4. **Salida de Detecciones:**\n",
        "   - La salida final consiste en las cajas delimitadoras seleccionadas despuÃ©s de la supresiÃ³n de no mÃ¡ximos, junto con las clases detectadas y sus respectivas probabilidades.\n",
        "\n",
        "**Arquitectura:**\n",
        "\n",
        "![yolov8_arciteture](https://user-images.githubusercontent.com/62583018/211719362-39fc8a88-b1ce-4ab3-9a9f-b640550515b4.jpg)"
      ],
      "metadata": {
        "id": "JRz0LNQETMvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Roboflow\n",
        "\n",
        "**[Roboflow](https://roboflow.com/)** es una plataforma que facilita el proceso de preparaciÃ³n de datos para proyectos de visiÃ³n por computadora y aprendizaje automÃ¡tico. Proporciona herramientas para organizar, limpiar, etiquetar y aumentar conjuntos de datos de imÃ¡genes de forma eficiente. AdemÃ¡s, facilita la creaciÃ³n de modelos de aprendizaje automÃ¡tico a travÃ©s de su plataforma.\n",
        "\n",
        "La preparaciÃ³n de un conjunto de datos personalizado puede representar un desafÃ­o considerable, pero como se mencionÃ³, Roboflow simplifica enormemente este proceso. A continuaciÃ³n, se describen los pasos seguidos para llevar a cabo este procedimiento:\n",
        "\n",
        "1. **CreaciÃ³n del Proyecto:** Se iniciÃ³ un proyecto especÃ­fico para la detecciÃ³n de objetos en Roboflow.\n",
        "2. **Subida de ImÃ¡genes:** Se subieron las imÃ¡genes recolectadas previamente al proyecto creado.\n",
        "3. **Etiquetado de Clases:** Se realizÃ³ el etiquetado de las clases de interÃ©s en las imÃ¡genes, como deforestaciÃ³n, agua, fuego y urbano.\n",
        "4. **Aumento de Datos:** Se aplicaron tÃ©cnicas de aumento de datos para mejorar la diversidad y cantidad de imÃ¡genes disponibles.\n",
        "5. **ExportaciÃ³n del Dataset:** Finalmente, se exportÃ³ el dataset preparado en el formato adecuado para su uso en el entorno de entrenamiento.\n",
        "\n",
        "[![Roboflow](https://i.ibb.co/kMrgGYL/Sin-t-tulo.png)](https://ibb.co/CWX5wxj)\n",
        "\n"
      ],
      "metadata": {
        "id": "pBd1GXdnaT2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DetecciÃ³n de DeforestaciÃ³n**"
      ],
      "metadata": {
        "id": "zT60EtBuk5wI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Descarga de las LibrerÃ­as**"
      ],
      "metadata": {
        "id": "ShjZ3utQc5hV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw2EMFzahSl0",
        "outputId": "15033730-a845-46d9-a29e-183b5d5f259c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# InstalaciÃ³n de paquetes necesarios\n",
        "!pip install ultralytics -q\n",
        "!pip install roboflow -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ImportaciÃ³n de librerÃ­as\n",
        "import glob\n",
        "import os\n",
        "\n",
        "from IPython.display import display, Image\n",
        "from roboflow import Roboflow\n",
        "import tensorflow as tf\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "f9fcIwGsixKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entorno de Trabajo**\n",
        "\n",
        "Es importante asegurarse de contar con acceso a una unidad de procesamiento grÃ¡fico (GPU) para garantizar un rendimiento Ã³ptimo durante el proceso."
      ],
      "metadata": {
        "id": "8HEQQkLderbV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9EcCFyYltYQ",
        "outputId": "8a377038-c700-428e-a9b4-7062988d998f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo GPU encontrado en: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "# Verificar si se encuentra disponible la GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "# Si no se encuentra disponible la GPU, lanzar una excepciÃ³n\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('No se encontrÃ³ dispositivo GPU')\n",
        "# Imprimir el nombre del dispositivo GPU encontrado\n",
        "print('Dispositivo GPU encontrado en: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define el directorio de trabajo actual\n",
        "HOME = os.getcwd()\n",
        "HOME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xYtmxxN9i6xe",
        "outputId": "29300a6e-98b3-4c2f-ab64-a3a472766e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset desde Roboflow**\n",
        "\n",
        "Como se mencionÃ³ anteriormente, se utilizÃ³ la herramienta de Roboflow para la creaciÃ³n del dataset. Para acceder al dataset, se puede utilizar la API de la siguiente manera. En caso de que no puedas acceder a la API, tambiÃ©n puedes descomprimir el archivo con el dataset que se encuentra en el repositorio."
      ],
      "metadata": {
        "id": "GCCgv6n7e6E4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets\n",
        "\n",
        "# Descargar el conjunto de datos de Roboflow utilizando la API de Roboflow\n",
        "rf = Roboflow(api_key=\"w2EZPylLkOYJSnI4o6qN\")\n",
        "project = rf.workspace(\"test-yyciu\").project(\"groot-v2\")\n",
        "version = project.version(3)\n",
        "dataset = version.download(\"yolov8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-gXImqhntGR",
        "outputId": "50818887-d739-4e59-9a99-234804634dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dependency ultralytics==8.0.196 is required but found version=8.2.28, to fix: `pip install ultralytics==8.0.196`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Groot-V2-3 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139468/139468 [00:04<00:00, 30198.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Groot-V2-3 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3996/3996 [00:00<00:00, 4300.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ValidaciÃ³n**"
      ],
      "metadata": {
        "id": "DDNhOMa5g6md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "# Validar los modelos\n",
        "models_path = f'{HOME}/models'\n",
        "\n",
        "for forestgroot_model in os.listdir(models_path):\n",
        "    if not forestgroot_model.lower().endswith('.pt'):\n",
        "      continue\n",
        "    model_name = ' '.join(forestgroot_model.split('_')[:2])\n",
        "    print(f\"****** Model: {model_name} ******\")\n",
        "    model_path = os.path.join(models_path, forestgroot_model)\n",
        "    forestgroot_seg = YOLO(model_path)\n",
        "    validation_results = forestgroot_seg.val()\n",
        "    print(\"****************************************\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8BMx5jti-rW",
        "outputId": "818c7733-a3cb-4242-d7db-fde4ddd1328b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "****** Model: forestgroot yolov8s ******\n",
            "Ultralytics YOLOv8.2.28 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8s-seg summary (fused): 195 layers, 11781148 parameters, 0 gradients, 42.4 GFLOPs\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 23.8MB/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/Groot-V2-3/valid/labels... 166 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:00<00:00, 1343.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/Groot-V2-3/valid/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:12<00:00,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        166        415       0.75      0.718      0.769      0.611       0.73      0.731      0.765      0.573\n",
            "         deforestation         37        106      0.826      0.623      0.763      0.679      0.784      0.632       0.75      0.638\n",
            "                  fire         39        100      0.695      0.773      0.789      0.665       0.69        0.8      0.801      0.632\n",
            "                 urban         68         93      0.703       0.71      0.758      0.474      0.685       0.72      0.741      0.417\n",
            "                 water         75        116      0.775      0.767      0.767      0.627      0.762      0.773      0.768      0.604\n",
            "Speed: 9.1ms preprocess, 13.1ms inference, 0.0ms loss, 9.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/val2\u001b[0m\n",
            "****************************************\n",
            "\n",
            "****** Model: forestgroot yolov9c ******\n",
            "WARNING âš ï¸ /content/models/forestgroot_yolov9c_seg.pt appears to require 'dill', which is not in ultralytics requirements.\n",
            "AutoInstall will run now for 'dill' but this feature will be removed in the future.\n",
            "Recommend fixes are to train a new model using the latest 'ultralytics' package or to run a command with an official YOLOv8 model, i.e. 'yolo predict model=yolov8n.pt'\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['dill'] not found, attempting AutoUpdate...\n",
            "Collecting dill\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 116.3/116.3 kB 3.6 MB/s eta 0:00:00\n",
            "Installing collected packages: dill\n",
            "Successfully installed dill-0.3.8\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 6.4s, installed 1 package: ['dill']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "Ultralytics YOLOv8.2.28 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv9c-seg summary (fused): 411 layers, 27627612 parameters, 0 gradients, 157.6 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/Groot-V2-3/valid/labels.cache... 166 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:00<?, ?it/s]\n",
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        166        415      0.768      0.755      0.782      0.639      0.772      0.754      0.785       0.58\n",
            "         deforestation         37        106      0.762      0.689       0.75      0.676      0.758      0.679      0.733      0.619\n",
            "                  fire         39        100      0.717       0.77      0.796      0.675      0.732       0.78      0.808      0.626\n",
            "                 urban         68         93      0.747      0.763      0.776      0.515      0.761      0.774      0.797      0.448\n",
            "                 water         75        116      0.845      0.798      0.805       0.69      0.839      0.784      0.805      0.626\n",
            "Speed: 3.2ms preprocess, 36.6ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/val3\u001b[0m\n",
            "****************************************\n",
            "\n",
            "****** Model: forestgroot yolov8n ******\n",
            "Ultralytics YOLOv8.2.28 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n-seg summary (fused): 195 layers, 3258844 parameters, 0 gradients, 12.0 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/Groot-V2-3/valid/labels.cache... 166 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:00<?, ?it/s]\n",
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        166        415      0.785      0.703      0.771      0.609      0.789      0.708      0.775      0.573\n",
            "         deforestation         37        106      0.766      0.698      0.742      0.659      0.754      0.689       0.74      0.616\n",
            "                  fire         39        100      0.805        0.7        0.8      0.675      0.816      0.712      0.807      0.645\n",
            "                 urban         68         93      0.747      0.688      0.762      0.492      0.756      0.701      0.771      0.449\n",
            "                 water         75        116      0.823      0.724       0.78      0.611      0.831      0.733      0.782      0.579\n",
            "Speed: 4.6ms preprocess, 10.7ms inference, 0.0ms loss, 5.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/val4\u001b[0m\n",
            "****************************************\n",
            "\n",
            "****** Model: forestgroot yolov8m ******\n",
            "Ultralytics YOLOv8.2.28 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8m-seg summary (fused): 245 layers, 27224700 parameters, 0 gradients, 110.0 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/Groot-V2-3/valid/labels.cache... 166 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:00<?, ?it/s]\n",
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:11<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        166        415      0.724      0.736      0.773      0.627      0.735      0.747      0.775      0.576\n",
            "         deforestation         37        106      0.736      0.689      0.751      0.689      0.737      0.689      0.749      0.625\n",
            "                  fire         39        100       0.66      0.737      0.774      0.631      0.659      0.735      0.773       0.61\n",
            "                 urban         68         93      0.717      0.753      0.759      0.494      0.758      0.796      0.776       0.45\n",
            "                 water         75        116      0.783      0.767      0.806      0.693      0.783      0.767      0.803      0.619\n",
            "Speed: 4.5ms preprocess, 28.2ms inference, 0.2ms loss, 3.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/val5\u001b[0m\n",
            "****************************************\n",
            "\n",
            "****** Model: forestgroot yolov8l ******\n",
            "Ultralytics YOLOv8.2.28 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8l-seg summary (fused): 295 layers, 45914972 parameters, 0 gradients, 220.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/Groot-V2-3/valid/labels.cache... 166 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:00<?, ?it/s]\n",
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:12<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        166        415      0.786      0.729      0.784      0.642      0.782      0.725       0.78      0.585\n",
            "         deforestation         37        106      0.803      0.693      0.765      0.699      0.803      0.693      0.766      0.645\n",
            "                  fire         39        100      0.745      0.758      0.805       0.67      0.745      0.759      0.804      0.643\n",
            "                 urban         68         93      0.766      0.656      0.758      0.504      0.765      0.656      0.761      0.428\n",
            "                 water         75        116      0.831       0.81      0.807      0.694      0.813      0.793      0.788      0.625\n",
            "Speed: 3.3ms preprocess, 43.4ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/val6\u001b[0m\n",
            "****************************************\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resultados del Modelo ForestGroot:**\n",
        "<div align=\"center\">\n",
        "\n",
        "| Modelo               | mAP50 <sub>box</sub> deforestation | mAP50<sub>mask</sub> deforestation | Params (M) |\n",
        "|----------------------|:----------------------------------:|:---------------------------------:|:----------:|\n",
        "| ForestGroot Yolov8n  |                0.742               |               0.74                |    3.26    |\n",
        "| ForestGroot Yolov8s  |               **0.763**            |               0.75                |   11.78    |\n",
        "| ForestGroot Yolov8m  |                0.751               |               0.749               |   27.22    |\n",
        "| ForestGroot Yolov8l  |               **0.765**            |             **0.766**             |   45.91    |\n",
        "| ForestGroot Yolov9c  |                0.75                |               0.73                |   27.63    |\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "GxWDawnHHGLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ElecciÃ³n del Modelo Final\n",
        "\n",
        "Para la elecciÃ³n del modelo final, despuÃ©s de realizar la validaciÃ³n de los modelos, tuvimos en cuenta principalmente la mÃ©trica **mAP50** (mean Average Precision at IoU=0.50). Los modelos que mejor rendimiento obtuvieron fueron el **ForestGroot YOLOv8L** y el **ForestGroot YOLOv9c**, ambos con un rendimiento de **0.78** en todas las clases, tanto en la detecciÃ³n de boxes como en mÃ¡scaras (masks).\n",
        "\n",
        "Sin embargo, dado que nuestro principal objetivo es la detecciÃ³n de la clase **deforestation**, la decisiÃ³n final se basÃ³ en el rendimiento especÃ­fico en esta clase. En este aspecto, el modelo **ForestGroot YOLOv8L** tuvo un rendimiento superior, alcanzando un **0.76** tanto en la detecciÃ³n de boxes como en mÃ¡scaras. En comparaciÃ³n, el **ForestGroot YOLOv9c** obtuvo un **0.75** en boxes y un **0.73** en mÃ¡scaras para la clase **deforestation**.\n",
        "\n",
        "Debido a esta diferencia en la clase mÃ¡s importante para nuestro proyecto, decidimos que el modelo **ForestGroot YOLOv8L** es el mÃ¡s adecuado para nuestro objetivo.\n"
      ],
      "metadata": {
        "id": "gVwvZyuShnj9"
      }
    }
  ]
}